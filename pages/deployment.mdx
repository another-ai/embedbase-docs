# Embedbase self-hosted

For any help or assistance with deployment, [book a demo](https://cal.com/potato/20min) and we will help you deploy your own instance.

## Using Supabase

1. Create a supabase project on https://supabase.com
2. Go to SQL Editor and run the following query to create the table

  ```sql
  create table documents (
    id text primary key,
    data text,
    embedding vector (1536),
    hash text,
    namespace text
  );
  ```

3. Create the search database function
  
  ```sql
  create or replace function match_documents (
    query_embedding vector(1536),
    similarity_threshold float,
    match_count int,
    query_namespace text
  )
  returns table (
    id text,
    data text,
    score float,
    hash text
  )
  language plpgsql
  as $$
  begin
    return query
    select
      documents.id,
      documents.data,
      (1 - (documents.embedding <=> query_embedding)) as similarity,
      documents.hash
    from documents
    where 1 - (documents.embedding <=> query_embedding) > similarity_threshold and query_namespace = documents.namespace
    order by documents.embedding <=> query_embedding
    limit match_count;
  end;
  $$;
  ```

4. Create the index

  ```sql
  create index on documents 
  using ivfflat (embedding vector_cosine_ops)
  with (lists = 100);
  ```

5. Add the following to your config.yaml file

```yaml
vector_database: supabase
supabase_url: "<get me here https://supabase.com>"
supabase_key: "<get me here https://supabase.com>"
openai_api_key: "<get me here https://platform.openai.com/account/api-keys>"
openai_organization: "<get me here https://platform.openai.com/account/org-settings>"
```

ðŸŽ‰ Now you should be able to run Embedbase with Supabase

```bash
docker-compose up
```

## Using Pinecone

Create an index on https://app.pinecone.io/ and add the index name to the config.yaml file.

```yaml
vector_database: pinecone
pinecone_index: "<get me here https://app.pinecone.io>"
pinecone_environment: "<get me here https://app.pinecone.io>"
pinecone_api_key: "<get me here https://app.pinecone.io>"
openai_api_key: "<get me here https://platform.openai.com/account/api-keys>"
openai_organization: "<get me here https://platform.openai.com/account/org-settings>"
```

ðŸŽ‰ Now you should be able to run Embedbase with Pinecone

```bash
docker-compose up
```

## Cloud Run deployment

Embedbase makes it easy for you to deploy your own instance. This assures you're in control of your data end to end.


### Setup

```bash
# login to gcloud
gcloud auth login

PROJECT_ID=$(gcloud config get-value project)

# Enable container registry
gcloud services enable containerregistry.googleapis.com

# Enable Cloud Run
gcloud services enable run.googleapis.com

# Enable Secret Manager
gcloud services enable secretmanager.googleapis.com

# create a secret for the config
gcloud secrets create EMBEDBASE --replication-policy=automatic

# add a secret version based on your yaml config
gcloud secrets versions add EMBEDBASE --data-file=config.yaml

IMAGE_URL="gcr.io/${PROJECT_ID}/embedbase:0.0.1"

docker buildx build . --platform linux/amd64 -t ${IMAGE_URL} -f ./docker/Dockerfile

docker push ${IMAGE_URL}

gcloud run deploy embedbase \
  --image ${IMAGE_URL} \
  --region us-central1 \
  --allow-unauthenticated \
  --set-secrets /secrets/config.yaml=EMBEDBASE:1

# getting cloud run url
gcloud run services list --platform managed --region us-central1 --format="value(status.url)" --filter="metadata.name=embedbase"
```
